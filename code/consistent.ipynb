{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff187cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg:chemistry_LessonPlan-Agent_chemistry.xlsx_一致性:0.6535251286882781\n",
      "avg:chemistry_ChatGPT4prompt_chemistry.xlsx_一致性:0.7918542643254812\n",
      "avg:chemistry_self-critique_chemistry.xlsx_一致性:0.633956072168292\n",
      "avg:chemistry_qwen72b_chemistry.xlsx_一致性:0.6822157543357539\n",
      "avg:chemistry_claude3-sonnet_chemistry.xlsx_一致性:0.6530880562907383\n",
      "avg:chemistry_GPT4-FAST_chemistry.xlsx_一致性:0.755015897278495\n",
      "avg:chemistry_GLM-4_chemistry.xlsx_一致性:0.6309950534948364\n",
      "avg:it_GLM-4_it.xlsx_一致性:0.6842999012582173\n",
      "avg:it_GPT4-FAST_it.xlsx_一致性:0.7132231098296549\n",
      "avg:it_qwen72b_it.xlsx_一致性:0.8801263457744877\n",
      "avg:it_self-critique_it.xlsx_一致性:0.8368473624000401\n",
      "avg:it_claude3-sonnet_it.xlsx_一致性:0.8332698170070788\n",
      "avg:it_LessonPlan-Agent_it.xlsx_一致性:0.8622803017523047\n",
      "avg:it_ChatGPT4prompt_it.xlsx_一致性:0.876731487835251\n",
      "avg:science_qwen72b_science.xlsx_一致性:0.9315858307491606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t2/08ygft8j4mz71tz3rv735ygc0000gp/T/ipykernel_36039/3926269320.py:49: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  sheets_name_dict = df_transposed.to_dict(orient='list')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg:science_LessonPlan-Agent_science.xlsx_一致性:0.6280890204644787\n",
      "avg:science_GLM-4_science.xlsx_一致性:0.7785166040366529\n",
      "avg:science_claude3-sonnet_science.xlsx_一致性:0.7197747491099244\n",
      "avg:science_self-critique_science.xlsx_一致性:0.7697519563522187\n",
      "avg:science_GPT4-FAST_science.xlsx_一致性:0.8983082217506133\n",
      "avg:science_ChatGPT4prompt_science.xlsx_一致性:0.7531504591058201\n",
      "avg:math_LessonPlan-Agent_math.xlsx_一致性:0.753879458981423\n",
      "avg:math_ChatGPT4prompt_math.xlsx_一致性:0.8228325264816373\n",
      "avg:math_claude3-sonnet_math.xlsx_一致性:0.8071123314695099\n",
      "avg:math_self-critique_math.xlsx_一致性:0.721038809183331\n",
      "avg:math_qwen72b_math.xlsx_一致性:0.6611012244042127\n",
      "avg:math_GPT4-FAST_math.xlsx_一致性:0.795769748964888\n",
      "avg:math_GLM-4_math.xlsx_一致性:0.6609374752091325\n",
      "avg:english_GPT4-FAST_english.xlsx_一致性:0.6652850832322643\n",
      "avg:english_self-critique_english.xlsx_一致性:0.6706560929239694\n",
      "avg:english_ChatGPT4prompt_english.xlsx_一致性:0.8277922167394538\n",
      "avg:english_qwen72b_english.xlsx_一致性:0.8560525456980816\n",
      "avg:english_LessonPlan-Agent_english.xlsx_一致性:0.6837058582773105\n",
      "avg:english_GLM-4_english.xlsx_一致性:0.8091701346582699\n",
      "avg:english_claude3-sonnet_english.xlsx_一致性:0.7437284733887076\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "\n",
    "subject = [\"math\", \"english\", \"chemistry\", \"science\", \"it\"]\n",
    "columns_to_drop = ['course information', 'textbook content','response','lesson_info','model name','60']\n",
    "root_dir = './result/consistent'\n",
    "save_dir = './result/consistent_csv'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "subject_rst = {}\n",
    "model_dict = {}\n",
    "model_dict_consistent = {}\n",
    "subject_list = []\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if not  file.endswith('.xlsx'): continue\n",
    "        subject_temp = root.split('/')[-1]\n",
    "        model_name = file.split('_')[0]\n",
    "        if subject_temp not in subject_rst:\n",
    "            subject_rst[subject_temp] = {}\n",
    "        file_name = file.split('.')[0]\n",
    "        if file_name in subject_rst[subject_temp]:\n",
    "            subject_rst[subject_temp][file_name] = None\n",
    "        sheets_dict = {}\n",
    "        file_path = os.path.join(root, file)\n",
    "        excel_file = pd.ExcelFile(file_path)\n",
    "        kappa_list = []\n",
    "        sheet_name_list = excel_file.sheet_names\n",
    "        for sheet_name in sheet_name_list:\n",
    "            sheet_name_excel = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "            \n",
    "                # sheet_name_excel = sheet_name_excel.drop(columns=['lesson_info','response'])\n",
    "            for col in columns_to_drop:\n",
    "                if col in sheet_name_excel.columns:\n",
    "                    sheet_name_excel = sheet_name_excel.drop(columns=[col])\n",
    "            sheet_name_excel.fillna(0, inplace=True)\n",
    "            # sheet_name_excel = sheet_name_excel\n",
    "            # if sheet_name == '刘润':\n",
    "            if  ('sigir' in root and ((subject_temp == 'english') or (subject_temp == 'science'))):\n",
    "                df_transposed = sheet_name_excel\n",
    "                # print(df_transposed)\n",
    "            else:\n",
    "                df_transposed = sheet_name_excel.transpose().reset_index()\n",
    "                # 设置新的列名\n",
    "                df_transposed.columns = df_transposed.iloc[0]\n",
    "                df_transposed = df_transposed.drop(0).reset_index(drop=True)\n",
    "            sheets_name_dict = df_transposed.to_dict(orient='list')\n",
    "            # print(sheets_name_dict)\n",
    "            # else:\n",
    "            # sheets_name_dict = sheet_name_excel.to_dict(orient='records')\n",
    "            sheets_dict[sheet_name] = {}\n",
    "            for key, value in sheets_name_dict.items():\n",
    "                # print('item', key, value)\n",
    "                key = str(key)\n",
    "                try:\n",
    "                    key_int = int(key)\n",
    "                except ValueError:\n",
    "                    key_int = None\n",
    "                    # key_int = key\n",
    "                if (('教研目录' in key) or (key_int is not None and 1 <= key_int <= 50)):\n",
    "                # if key != 'id' and key != '均值' and key != 'model name' and key != 'model' and key != 'lesson_info' and key != 'response' and key != 'textbook' and key != '内容准确性' and key != '内容一致性' and key != '语言逻辑性' and '序号' not in key and '总分' not in key:\n",
    "                    if key not in sheets_dict[sheet_name]:\n",
    "                        sheets_dict[sheet_name][key] = value\n",
    "                    # sheets_dict[sheet_name][key].append(value)\n",
    "            \n",
    "        # print(sheets_dict)\n",
    "        kappa_mean_list = []\n",
    "        new_data = []\n",
    "        # print(sheets_dict[sheet_name_list[0]])\n",
    "        result_sum = []\n",
    "        result_len = 0\n",
    "        for key, value in sheets_dict[sheet_name_list[0]].items():\n",
    "            # print(key)\n",
    "            # print(value, value2, value3)\n",
    "            value2 = sheets_dict[sheet_name_list[1]][key]\n",
    "            value3 = sheets_dict[sheet_name_list[2]][key]\n",
    "            kappa_12 = cohen_kappa_score(value, value2)\n",
    "            kappa_13 = cohen_kappa_score(value, value3)\n",
    "            kappa_23 = cohen_kappa_score(value2, value3)\n",
    "            if np.isnan([kappa_12]).any():\n",
    "                kappa_12 = 1\n",
    "            if np.isnan([kappa_13]).any():\n",
    "                kappa_13 = 1\n",
    "            if np.isnan([kappa_23]).any():\n",
    "                kappa_23 = 1\n",
    "            kappa_mean_list.append(np.mean([kappa_12, kappa_13, kappa_23]))\n",
    "            # print(subject_temp,file_name,key, kappa_12, kappa_13, kappa_23, np.mean([kappa_12, kappa_13, kappa_23]))\n",
    "            temp_list = [subject_temp, file_name, key, kappa_12, kappa_13, kappa_23, np.mean([kappa_12, kappa_13, kappa_23])]\n",
    "            result_sum += value+value2+value3\n",
    "            new_data.append(temp_list)\n",
    "            # result_len += len(value+value2+value3)\n",
    "        result_sum = [float(x) for x in result_sum]\n",
    "        new_df = pd.DataFrame(new_data, columns=['subject', 'file_name', 'id', 'kappa_12', 'kappa_13', 'kappa_23', 'kappa_mean'])\n",
    "        new_df.to_csv(f'{save_dir}/'+subject_temp+file_name+'.csv', index=False)\n",
    "        if model_name not in model_dict:\n",
    "            model_dict[model_name] = {}\n",
    "        if subject_temp not in model_dict[model_name]:\n",
    "            model_dict[model_name][subject_temp] = []\n",
    "        if subject_temp not in subject_list:\n",
    "            subject_list.append(subject_temp)\n",
    "        model_dict[model_name][subject_temp].append(np.sum(result_sum)/len(result_sum))\n",
    "        if model_name not in model_dict_consistent:\n",
    "            model_dict_consistent[model_name] = {}\n",
    "        if subject_temp not in model_dict_consistent[model_name]:\n",
    "            model_dict_consistent[model_name][subject_temp] = []\n",
    "        model_dict_consistent[model_name][subject_temp].append(np.mean(kappa_mean_list))\n",
    "        model_dict[model_name][subject_temp].append(np.sum(result_sum)/len(result_sum))\n",
    "        # print(len(result_sum))\n",
    "        # # subject_rst[subject_temp][file_name] = np.mean(kappa_mean_list)\n",
    "        print(f\"avg:{subject_temp}_{file}_一致性:{np.mean(kappa_mean_list)}\")\n",
    "        # print(f\"avg:{subject_temp}_{file}_结果数量:{len(result_sum)}, 结果sum:{np.sum(result_sum)},结果平均值:{np.sum(result_sum)/len(result_sum)}) \")\n",
    "# print(subject_list)\n",
    "# print(model_dict)\n",
    "        \n",
    "new_data = []    \n",
    "for key, value in model_dict.items():\n",
    "    # for subject in model_dict[key]:\n",
    "    # print(key,value)\n",
    "    temp = [key]\n",
    "    for subject in subject_list:\n",
    "        try:\n",
    "            temp.append(round(float(value[subject][0]),3))\n",
    "        except:\n",
    "            temp.append(0)\n",
    "            \n",
    "        # print(temp)\n",
    "    new_data.append(temp)\n",
    "# print(new_data[0])\n",
    "df = pd.DataFrame(new_data, columns=['model_name']+subject_list)\n",
    "df.to_csv(f\"{save_dir}/result.csv\", index=False)       \n",
    "            \n",
    "new_data = []    \n",
    "for key, value in model_dict_consistent.items():\n",
    "    # for subject in model_dict[key]:\n",
    "    # print(key,value)\n",
    "    temp = [key]\n",
    "    for subject in subject_list:\n",
    "        try:\n",
    "            temp.append(value[subject][0])\n",
    "        except:\n",
    "            temp.append(0)\n",
    "            \n",
    "        # print(temp)\n",
    "    new_data.append(temp)\n",
    "# print(new_data[0])\n",
    "df = pd.DataFrame(new_data, columns=['model_name']+subject_list)\n",
    "df.to_csv(f\"{save_dir}/result_consistent.csv\", index=False)              \n",
    "# sheets_dict                \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e388b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
