{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff187cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg:chemistry_LessonPlan-Agent_chemistry.xlsx_consistent:0.6745746653559479\n",
      "avg:chemistry_ChatGPT4prompt_chemistry.xlsx_consistent:0.8542426078103368\n",
      "avg:chemistry_self-critique_chemistry.xlsx_consistent:0.6562902222473713\n",
      "avg:chemistry_qwen72b_chemistry.xlsx_consistent:0.7037002269009138\n",
      "avg:chemistry_claude3-sonnet_chemistry.xlsx_consistent:0.6727732903937349\n",
      "avg:chemistry_GPT4-FAST_chemistry.xlsx_consistent:0.7792827730137973\n",
      "avg:chemistry_GLM-4_chemistry.xlsx_consistent:0.6547259056454737\n",
      "avg:it_GLM-4_it.xlsx_consistent:0.6952399622658288\n",
      "avg:it_GPT4-FAST_it.xlsx_consistent:0.7317450019902294\n",
      "avg:it_qwen72b_it.xlsx_consistent:0.8953262871253884\n",
      "avg:it_self-critique_it.xlsx_consistent:0.8580739136009656\n",
      "avg:it_claude3-sonnet_it.xlsx_consistent:0.8332698170070788\n",
      "avg:it_LessonPlan-Agent_it.xlsx_consistent:0.8789600022286379\n",
      "avg:it_ChatGPT4prompt_it.xlsx_consistent:0.8905572454110086\n",
      "avg:science_qwen72b_science.xlsx_consistent:0.9315858307491606\n",
      "avg:science_LessonPlan-Agent_science.xlsx_consistent:0.6413839415058786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t2/08ygft8j4mz71tz3rv735ygc0000gp/T/ipykernel_5976/2864524538.py:49: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  sheets_name_dict = df_transposed.to_dict(orient='list')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg:science_GLM-4_science.xlsx_consistent:0.7990386082635592\n",
      "avg:science_claude3-sonnet_science.xlsx_consistent:0.7431044285834185\n",
      "avg:science_self-critique_science.xlsx_consistent:0.7894030092168481\n",
      "avg:science_GPT4-FAST_science.xlsx_consistent:0.8983082217506133\n",
      "avg:science_ChatGPT4prompt_science.xlsx_consistent:0.7679057123972693\n",
      "avg:math_LessonPlan-Agent_math.xlsx_consistent:0.7696011907120899\n",
      "avg:math_ChatGPT4prompt_math.xlsx_consistent:0.8356487791956628\n",
      "avg:math_claude3-sonnet_math.xlsx_consistent:0.8298127482717105\n",
      "avg:math_self-critique_math.xlsx_consistent:0.7361607358414591\n",
      "avg:math_qwen72b_math.xlsx_consistent:0.6822510593619335\n",
      "avg:math_GPT4-FAST_math.xlsx_consistent:0.8005304600966554\n",
      "avg:math_GLM-4_math.xlsx_consistent:0.6837919082203177\n",
      "avg:english_GPT4-FAST_english.xlsx_consistent:0.6835418287745585\n",
      "avg:english_self-critique_english.xlsx_consistent:0.6976225920726316\n",
      "avg:english_ChatGPT4prompt_english.xlsx_consistent:0.849930535154139\n",
      "avg:english_qwen72b_english.xlsx_consistent:0.885786328234247\n",
      "avg:english_LessonPlan-Agent_english.xlsx_consistent:0.7067274410111233\n",
      "avg:english_GLM-4_english.xlsx_consistent:0.8065026657453137\n",
      "avg:english_claude3-sonnet_english.xlsx_consistent:0.7652855532762187\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "subject = [\"math\", \"english\", \"chemistry\", \"science\", \"it\"]\n",
    "columns_to_drop = ['course information', 'textbook content','response','lesson_info','model name','60']\n",
    "root_dir = './result/consistent'\n",
    "save_dir = './result/consistent_csv'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "subject_rst = {}\n",
    "model_dict = {}\n",
    "model_dict_consistent = {}\n",
    "subject_list = []\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if not  file.endswith('.xlsx'): continue\n",
    "        subject_temp = root.split('/')[-1]\n",
    "        model_name = file.split('_')[0]\n",
    "        if subject_temp not in subject_rst:\n",
    "            subject_rst[subject_temp] = {}\n",
    "        file_name = file.split('.')[0]\n",
    "        if file_name in subject_rst[subject_temp]:\n",
    "            subject_rst[subject_temp][file_name] = None\n",
    "        sheets_dict = {}\n",
    "        file_path = os.path.join(root, file)\n",
    "        excel_file = pd.ExcelFile(file_path)\n",
    "        kappa_list = []\n",
    "        sheet_name_list = excel_file.sheet_names\n",
    "        for sheet_name in sheet_name_list:\n",
    "            sheet_name_excel = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "            \n",
    "                # sheet_name_excel = sheet_name_excel.drop(columns=['lesson_info','response'])\n",
    "            for col in columns_to_drop:\n",
    "                if col in sheet_name_excel.columns:\n",
    "                    sheet_name_excel = sheet_name_excel.drop(columns=[col])\n",
    "            sheet_name_excel.fillna(0, inplace=True)\n",
    "            # sheet_name_excel = sheet_name_excel\n",
    "            # if sheet_name == '刘润':\n",
    "            if  ('sigir' in root and ((subject_temp == 'english') or (subject_temp == 'science'))):\n",
    "                df_transposed = sheet_name_excel\n",
    "                # print(df_transposed)\n",
    "            else:\n",
    "                df_transposed = sheet_name_excel.transpose().reset_index()\n",
    "                # 设置新的列名\n",
    "                df_transposed.columns = df_transposed.iloc[0]\n",
    "                df_transposed = df_transposed.drop(0).reset_index(drop=True)\n",
    "            sheets_name_dict = df_transposed.to_dict(orient='list')\n",
    "            # print(sheets_name_dict)\n",
    "            # else:\n",
    "            # sheets_name_dict = sheet_name_excel.to_dict(orient='records')\n",
    "            sheets_dict[sheet_name] = {}\n",
    "            for key, value in sheets_name_dict.items():\n",
    "                # print('item', key, value)\n",
    "                key = str(key)\n",
    "                try:\n",
    "                    key_int = int(key)\n",
    "                except ValueError:\n",
    "                    key_int = None\n",
    "                    # key_int = key\n",
    "                if ((key_int is not None and 1 <= key_int <= 50)):\n",
    "                    if key not in sheets_dict[sheet_name]:\n",
    "                        sheets_dict[sheet_name][key] = value\n",
    "                    # sheets_dict[sheet_name][key].append(value)\n",
    "            \n",
    "        # print(sheets_dict)\n",
    "        kappa_mean_list = []\n",
    "        new_data = []\n",
    "        # print(sheets_dict[sheet_name_list[0]])\n",
    "        result_sum = []\n",
    "        result_len = 0\n",
    "        for key, value in sheets_dict[sheet_name_list[0]].items():\n",
    "            # print(key)\n",
    "            # print(value, value2, value3)\n",
    "            \n",
    "            value2 = sheets_dict[sheet_name_list[1]][key]\n",
    "            value3 = sheets_dict[sheet_name_list[2]][key]\n",
    "            value = [math.floor(float(i)) for i in value]\n",
    "            value2 = [math.floor(float(i)) for i in value2]\n",
    "            value3 = [math.floor(float(i)) for i in value3]\n",
    "            kappa_12 = cohen_kappa_score(value, value2)\n",
    "            kappa_13 = cohen_kappa_score(value, value3)\n",
    "            kappa_23 = cohen_kappa_score(value2, value3)\n",
    "            if np.isnan([kappa_12]).any():\n",
    "                kappa_12 = 1\n",
    "            if np.isnan([kappa_13]).any():\n",
    "                kappa_13 = 1\n",
    "            if np.isnan([kappa_23]).any():\n",
    "                kappa_23 = 1\n",
    "            kappa_mean_list.append(np.mean([kappa_12, kappa_13, kappa_23]))\n",
    "            # print(subject_temp,file_name,key, kappa_12, kappa_13, kappa_23, np.mean([kappa_12, kappa_13, kappa_23]))\n",
    "            temp_list = [subject_temp, file_name, key, kappa_12, kappa_13, kappa_23, np.mean([kappa_12, kappa_13, kappa_23])]\n",
    "            result_sum += value+value2+value3\n",
    "            new_data.append(temp_list)\n",
    "            # result_len += len(value+value2+value3)\n",
    "        result_sum = [float(x) for x in result_sum]\n",
    "        new_df = pd.DataFrame(new_data, columns=['subject', 'file_name', 'id', 'kappa_12', 'kappa_13', 'kappa_23', 'kappa_mean'])\n",
    "        new_df.to_csv(f'{save_dir}/'+subject_temp+file_name+'.csv', index=False)\n",
    "        if model_name not in model_dict:\n",
    "            model_dict[model_name] = {}\n",
    "        if subject_temp not in model_dict[model_name]:\n",
    "            model_dict[model_name][subject_temp] = []\n",
    "        if subject_temp not in subject_list:\n",
    "            subject_list.append(subject_temp)\n",
    "        model_dict[model_name][subject_temp].append(np.sum(result_sum)/len(result_sum))\n",
    "        if model_name not in model_dict_consistent:\n",
    "            model_dict_consistent[model_name] = {}\n",
    "        if subject_temp not in model_dict_consistent[model_name]:\n",
    "            model_dict_consistent[model_name][subject_temp] = []\n",
    "        model_dict_consistent[model_name][subject_temp].append(np.mean(kappa_mean_list))\n",
    "        model_dict[model_name][subject_temp].append(np.sum(result_sum)/len(result_sum))\n",
    "        \n",
    "        print(f\"avg:{subject_temp}_{file}_consistent:{np.mean(kappa_mean_list)}\")\n",
    "        \n",
    "new_data = []    \n",
    "for key, value in model_dict.items():\n",
    "    # for subject in model_dict[key]:\n",
    "    # print(key,value)\n",
    "    temp = [key]\n",
    "    for subject in subject_list:\n",
    "        try:\n",
    "            temp.append(round(float(value[subject][0]),3))\n",
    "        except:\n",
    "            temp.append(0)\n",
    "            \n",
    "        # print(temp)\n",
    "    new_data.append(temp)\n",
    "# print(new_data[0])\n",
    "df = pd.DataFrame(new_data, columns=['model_name']+subject_list)\n",
    "df.to_csv(f\"{save_dir}/result.csv\", index=False)       \n",
    "            \n",
    "new_data = []    \n",
    "for key, value in model_dict_consistent.items():\n",
    "    # for subject in model_dict[key]:\n",
    "    # print(key,value)\n",
    "    temp = [key]\n",
    "    for subject in subject_list:\n",
    "        try:\n",
    "            temp.append(value[subject][0])\n",
    "        except:\n",
    "            temp.append(0)\n",
    "            \n",
    "        # print(temp)\n",
    "    new_data.append(temp)\n",
    "# print(new_data[0])\n",
    "df = pd.DataFrame(new_data, columns=['model_name']+subject_list)\n",
    "df.to_csv(f\"{save_dir}/result_consistent.csv\", index=False)              \n",
    "# sheets_dict                \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e388b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
